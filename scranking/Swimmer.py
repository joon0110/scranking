import requests
from bs4 import BeautifulSoup


class Swimmer:
    """
    A class representing a swimmer for Swimcloud website
    """

    def __init__(self, url):
        """
        Initialize the Swimmer object.
        """
        self.url = url
        self.event_list = []

    def get_http_status(self):
        """
        Check if the Swimcloud website is working.

        :return: The status code of the website.
        """
        response = requests.get(self.url)
        if not response:
            return "Connection fail"
        else:
            return response.status_code

    def get_soup(self):
        """
        Create a bf4 for the input url.

        :return: BeautifulSoup of the input url.
        """
        response = requests.get(self.url)
        soup = BeautifulSoup(response.content, 'html.parser')
        if not soup:
            return "Not possible to parse"
        else:
            return soup

    def save_soup_to_file(self, soup, filename):
        """
        Create a txt file that contains the html of the input website to see with eyes.

        """
        with open(filename, "w") as f:
            f.write(str(soup))

    def get_name(self, soup):
        """
        Gets the name of the swimmer.

        :param soup: The BeautifulSoup you created from get_soup() method.
        :return: A full name of the swimmer.
        """
        name = soup.find('title')
        titleString = name.string
        s1 = titleString.replace("| Swimcloud", "", 1).replace('\n', '').strip()  # noqa

        if not s1:
            return None
        else:
            return s1

    # if use the soup that is generated by get_soup method, it does not correctly output the hometown and uni
    def get_info(self, html):
        """
        Get the social network informnations of the swimmer
        """
        newsoup = BeautifulSoup(html, 'html.parser')
        hometown = newsoup.find('li').get_text()
        university = newsoup.find('a').get_text()

        social_links = newsoup.find_all('a', class_='btn-icon-plain')
        for link in social_links:
            title = link.get('title')
            if 'Twitter' in title:
                twitter = link['href']
            elif 'Instagram' in title:
                instagram = link['href']

        return f"Hometown: {hometown}, University: {university}, Twitter: {twitter}, Instagram: {instagram}"  # noqa

    def get_event(self, soup):
        rows = soup.select('#js-swimmer-profile-times-container tbody tr')

        results = []
        for row in rows:
            event_name = row.select_one('td:nth-of-type(1)').text.strip()
            time = row.select_one('td:nth-of-type(2) a').text.strip()
            results.append(f'{event_name}: {time}')
        self.event_list = results

        return results

    def lookup_event(self, event_name):
        for event in self.event_list:
            if event_name in event:
                return event
        return f'{event_name} not found'
